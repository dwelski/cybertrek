<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CyberTrek</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 0;
      background-color: #0d1117;
      color: #c9d1d9;
    }
    header {
      background: #161b22;
      padding: 2rem;
      text-align: center;
    }
    header h1 {
      margin: 0;
      font-size: 2.5rem;
      color: #58a6ff;
    }
    main {
      padding: 2rem;
      max-width: 800px;
      margin: auto;
    }
    h2, h3 {
      color: #58a6ff;
    }
    img {
      max-width: 100%;
      display: block;
      margin: 1.5rem auto;
      border-radius: 8px;
    }
    footer {
      background: #161b22;
      padding: 1rem;
      text-align: center;
      font-size: 0.9rem;
      color: #8b949e;
      margin-top: 3rem;
    }
    a {
      color: #58a6ff;
      text-decoration: none;
    }
    blockquote {
      border-left: 4px solid #58a6ff;
      padding-left: 1rem;
      color: #9da5b4;
      font-style: italic;
    }
  </style>
</head>
<body>
  <header>
    <h1>üöÄ CyberTrek</h1>
    <p>Your guide through the wild terrain of AI threats, vulnerabilities, and harms</p>
  </header>

  <main>
    <h2>Welcome to CyberTrek</h2>
    <p>
      I‚Äôm a (mostly) reformed AI doomer trying to keep up with the breakneck pace of innovation 
      and share what I uncover along the way‚Äîespecially where security still lags behind capability.
    </p>

    <p>Let‚Äôs start in the woods of the Borscht Belt:</p>

    <img src="Screenshot-2025-07-13-4.17.51PM.png" alt="Summer camp screenshot">

    <p>
      I remember "hunting" for salamanders (aggressive terminology, but no salamanders were harmed) 
      at summer camp, just after a heavy rain; flipping over logs to catch that sudden flash of bright orange 
      nestled in the moss or leaves. We‚Äôd cobble together terrariums from whatever we could find 
      (twigs, dirt, water) without really knowing what the salamanders actually needed to survive.
    </p>

    <blockquote>We meant well, but we were experimenting in the dark.</blockquote>

    <img src="image.png" alt="Salamander memory">

    <p>
      That memory reminds me of how we approach AI systems today. We build large-scale LLMs, agents, 
      and recommendation engines with major real-world impact; and then race to bolt on security after 
      they‚Äôre deployed.
    </p>

    <p>
      Take LLMs: we often focus on their social or economic risks, but the technical attack surface is just as urgent. 
      Trends like vibe coding, no-code agents, and plug-and-play model deployment are lowering the barrier to entry‚Äîand raising the stakes.
    </p>

    <p>
      The reality is GenAI is already in use, whether or not teams realize it. From CRM to productivity co-pilots 
      and third-party SaaS platforms, AI is being woven into daily operations.
    </p>

    <p>
      And when these tools fall into the wrong hands (or even well-meaning hands without guardrails), the risks multiply. 
      Misuse, misconfigurations, and adversarial manipulation can escalate fast.
    </p>

    <blockquote>
      That‚Äôs why raising awareness among engineering teams, security leaders, and CTOs matters now (left of boom) 
      and not when it‚Äôs too late (right of boom).
    </blockquote>

    <img src="cf8c35c4.png" alt="LLM risk illustration">

    <p>
      Many threats feel new. Take the jailbreak prompts eliciting restricted content (nuclear instructions, anyone?) 
      but LLMs are still cloud-native systems. They suffer from the same age-old flaws: poor input validation, weak 
      access controls, insecure dependencies. In some cases, this is just new tech wrapped in familiar vulnerabilities 
      (e.g. OWASP Top 10 Web Apps vs. OWASP Top 10 for LLMs).
    </p>

    <img src="1747427335615.jpg" alt="AI threat landscape">

    <p>
      This isn‚Äôt just about edge cases or FUD. It‚Äôs about what happens when AI systems become embedded in our infrastructure, 
      our decisions, and our culture before we fully understand how to secure them.
    </p>

    <p>
      Thanks for reading, and happy trekking.
    </p>

    <p><em>
      This is the first in a series on AI threat modeling, security tradeoffs, and the terrain ahead. 
      Let‚Äôs navigate it together: logs, moss, hallucinations, and all.
    </em></p>

    <h2>About Me</h2>
    <p>
      Hi! My name is <strong>Derek Welski</strong>. I‚Äôm passionate about building safer, more accountable AI systems 
      by connecting emerging technology with the ‚Äúhuman‚Äù layer of AI security and AI governance. 
      My career has taken me from field research in Kosovo to ad tech, and I hope that this broad perspective 
      makes my content more relatable and accessible.
    </p>

    <img src="Screenshot-2025-07-13-4.22.40PM.png" alt="About Derek Welski">
  </main>

  <footer>
    <p>¬© 2025 CyberTrek | Built with <a href="https://pages.github.com/" target="_blank">GitHub Pages</a></p>
  </footer>
</body>
</html>
